{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "import chromedriver_autoinstaller as ca\n",
    "import math, os, time, urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "본 논문에서 제안한 빅데이터 기반 시공간 센서 데이터 처리 시스템은 센서에서 발생한 데이터를 수집하고 저장하여 이를 분석하고 그 결과에 따라 주요 의사 결정을 하는 응용시스템에서 활용가능하며 WSN의 후위(back-end)시스템은 정보계시스템으로 유용한 시스템임을 플랫폼 평가에서 보여주었다. 향후 연구 방향으로는 수집 저장된 시공간데이터를 가지고 다양한 분석을 할 수 있도록 빅데이터 분석 모델 개발에 대한 연구가 지속적으로 이루어져야 한다고 본다. 저장 과정에서는 대용량 파일을 분산 저장하고 병렬 처리하기 위하여 Hadoop HDFS와 MapReduce를 적용하였다.해 적합한 Hadoop ECO System과, 빅데이터 분석을 위한 회귀분석, 군집분석, 시계열 분석 등의 다양한 분석 기술은 R을 사용하여 Hadoop시스템과 연동되어 구동되며 본 논문의 핵심 기술로써 활용된다.드간 라우팅 기술, 쿼리시 죠인 전략 등과 같은 쿼리 처리 기술 등이 있으며 데이터 저장 방식도 지역 저장 방식(local storage), 데이터 중심 저장 방식(Data Centric Storage)을 선호해 왔다.  is designed and implemented in this paper processes the big data through 5 steps consisting of aggregating, storing, processing, analysing and visualizing. The HDFS was adopted as a distributing file system and MapReduce was used to process the data parallely. And in the pre-refining stage of big data, the Pig and Hive which runs over the Hadoop was used and in the final stage the R program was used to analyse the big data and show the result visually. First in all, user defined spatio-temporal data type and its opertor was defined and used in the analysis step using R for the first time and the test result showed this proposed system can be useful in the various application. 컴퓨팅 기술의 비약적인 발전과 무선통신 기술의 발전에 힘입어 무선네트워크로 연결된 위치기반 센서 노드들에서 수집되는 시공간데이터를 활용한 응용에 대한 요구가 증가하고 있다. query  rather than the centralized query processing was mainly studied. The representative technology studied so far is routing protocol, query processing technique like joining strategy and data storing method such as  local storage and data centric storage. The centralized query processing is the external processing way out of the network after collecting and saving the sensed data in the base station or sink node. The centralized data processing way can be preferred to the in-network processing for the complex query and big data analysis using the collected data. So in my thesis, I propose the combined way called hybrid way to meet these two needs. The way to improve the performance and efficiency in in-network processing was added to the existing query processing system to get the result of ad-hoc query efficiently as a front-end system and also I proposed the centralized processing system as a back-end system to get the result of complex query efficiently using the saved sensed data or historical data for the further big data analysis. I deployed and proposed the spatio-temporal data type and its operator in the existing spatial tinyDB for the efficient query by following the OGC(Open Geospatial Consortium) suggestion. Aso I proposed the input filtering module, memory sharing module to improve the performance of query in the front-end system. The back-end system to process the collected sensed data in a centralized way to overcome the limits of sensor node such as processor power, small memory and battery  is also strongly needed for big data processing and analysis like regression analysis, correlation analysis, cluster analysis and time series analysis by distributing the sensed data and using the parallel processing.\n",
      "원문보기\n",
      "목차검색조회\n",
      "음성듣기\n",
      "2빅데이터 마이닝에 의한 공시지가 민원의 시공간적 특성 분석조태인인천대학교2016국내박사RANK : 13880191원문보기목차검색조회음성듣기최근 다양한 분야에서 다량의 정형 및 비정형 자료, 즉 빅데이터를 분석하여 자료의 연관성을 규명하고 미래전략을 수립하는 방법이 활용되고 있다. 공시지가의 경우에도 지역적 및 시간적으로 다양하고 복잡한 민원이 제기되고 있어 빅데이터를 활용하여 이를 효과적으로 분석하고 관리하는 방법에 관한 연구가 필요하다. 이 연구의 목적은 빅데이터 마이닝에 의해서 공시지가 민원의 시공간적 특성 분석 방법을 정립하는 것이다. 특히 이 연구는 제도적인 측면보다는 공시지가 민원 발생의 시공간적 원인 분석에 주안점을 두고, 그 변화 추세를 모니터링 할 수 있는 표준화 모델을 정립하고자 하였다.연구 수행을 위해서 빅데이터 마이닝에 의한 공시지가 민원의 시공간적 특성 분석 표준화 모델을 정립하였다. 그리고 시간과 공간적인 속성을 함께 포함하고 있는 2006년부터 2015년까지의 인천광역시 중구의 공시지가 민원자료 6,481건을 수집하고, 이것을 공간정보와 결합하여 공간 빅데이터 기반의 공시지가 민원정보 데이터베이스를 구축하였다. 텍스트 마이닝 방법을 이용하여 주요 키워드의 빈도를 분석하고, 소셜 네트워크 분석을 통해서 주요 키워드들의 상호 연관성을 파악하였다. 키워드 가중치를 산출하여 공시지가 민원발생 관심 키워드를 선정한 후, 국지적 자기상관의 지표인 G 통계량(Getis-Ord Gi*)을 적용한 핫스팟 분석을 통하여 시공간적 특성을 분석하였다.연구 결과, 공시지가 민원의 특성은 시공간적으로 연계된 군집 형태를 형성하면서 변화하고 있음을 알 수 있었다. 텍스트 마이닝과 소셜 네트워크 분석 방법을 이용하여 자연어 기반의 공시지가 민원에 대한 발생 원인을 정량적으로 규명할 수 있음을 알 수 있었으며, 키워드 가중치인 단어 빈도(TF) 및 단어 빈도와 역문서 빈도의 조합값(TF-IDF)의 상대적인 차이가 있어 시공간적인 민원 특성을 분석하기 위한 주요 설명변수로 활용될 수 있음을 알 수 있었다. Recently, a method of analyzing structured as well as unstructured data, the so-called big data, has been widely applied for creating valuable information to use it for a future strategy in various fields. With respect to the officially assessed land price, there have been many civil complaints that are complex and diverse in terms of both region and time. Thus, more research should be done in order to effectively examine and manage such complaints by applying the big data. The purpose of this study is to establish a method of analyzing spatio-temporal characteristics of the civil complaints for the officially assessed land price based on big data mining. Specifically, this study is established the underlying reasons for the civil complaints from the spatio-temporal perspectives, rather than the institutional factors, and to suggest a model of monitoring a trend of the occurrence of such complaints.The official documents of 6,481 civil complaints for the officially assessed land price in the district of Jung-gu of Incheon Metropolitan City over the period from 2006 to 2015 along with their temporal and spatial properties were collected and used for the analysis. Frequencies of major key words were examined by using a text mining method. Correlations among major key words were studied through the social network analysis. By calculating Term Frequency(TF) and Term Frequency-Inverse Document Frequency(TF-IDF), which correspond to the weighted value of key words, I identified the major key words of interest for the occurrence of the civil complaint for the officially assessed land price were selected. Then, the spatio-temporal characteristics of the civil complaints were examined by analyzing hot spot based on the statistics of Getis-Ord Gi*. It was found that the civil complaints for the officially assessed land price vary in a cluster that changes spatio-temporally. This study shows the proposed standard model can identify the causes of the occurrence of the civil complaints which is written in natural language for the officially assessed land price quantitatively through text mining and social-network analysis method. In addition, TF and TF-IDF, the weighted averages of key words, can be used as main explanatory variables to analyze spatio-temporal characteristics of civil complaints for the officially assessed land price since these statistics are different over time across different regions.\n",
      "원문보기\n",
      "목차검색조회\n",
      "음성듣기\n",
      " Finally, analyzing the whole text of a thesis using big data analysis method in future trend analysis seems to be more reliable data analysis. It is also necessary to study not only social science and engineering but also humanities, natural sciences and arts and physical education.ud of R program. in the social science field and the technology related fields such as network and algorithm were high in the comparative analysis. Even if we look at the status by year, researches on network science, cloud, database in the field of personal information protection, network, cloud and engineering have been steadily studied. In the comparative analysis of social issues, social science field reflects social trends and issues related to each year.\n",
      "원문보기\n",
      "목차검색조회\n",
      "음성듣기\n",
      "4빅데이터 응용사례 분석을 통한 소스데이터 유형 분류 : BI&A 응용분야와 U-City 서비스 분류체계를 중심으로이현구단국대학교 대학원2014국내석사RANK : 13880191원문보기목차검색조회음성듣기최근 스마트 모바일 기기의 확산, 소셜네트워크 서비스의 활성화, 기업의 고객데이터 수집, 동영상 콘텐츠의 증가에 힘입어 정보의 양이 기하급수적으로 증가하고 있다. 이러한 빅데이터는 과거에는 별도로 보관 및 저장하지 않고 흘려버려지는 데이터들이었다. 하지만 지금은 분석기술의 발달, 저장매체 가격의 하락에 힘입어 이를 분석함으로써 비즈니스의 효율화, 개인맞춤화, 미래예측 등 비즈니스 부문의 혁신을 이루어낼 수 있음은 물론이다. 나아가 장기적으로는 지식기반 사회에서 일어나는 다양한 사회현상에 대한 통찰력, 대응력, 경쟁력, 창조력을 제공하고 있다. 본 연구의 목적은 빅데이터의 다양한 응용사례들을 BI&A 응용분야의 기준과 U-City 서비스 유형에 따라 분류하고 데이터의 특성을 분석함으로써 향후 다양한 분야에서의 빅데이터의 활용 및 발전방안 모색을 위한 시사점을 제시하는 것이다. 국내외 빅데이터로 소개된 사례를 조사하고 중복, 빅데이터와 무관한 사례를 제외한 58개 사례를 정리하였다. 관련연구의 문헌고찰을 통하여 BI&A의 5대 분류기준과 유비쿼터스도시건설등에관한법률 시행령 상의 10대 서비스 분류체계를 조합한 5x10 매트릭스 형태의 분류체계를 를 고안하였고 본 분류체계에 따라 데이터의 구조적․비구조적, 내부․외부 데이터의 특성을 분석하였다.\n",
      "원문보기\n",
      "목차검색조회\n",
      "음성듣기\n",
      "5빅데이터를 활용한 뉴스 콘텐츠가 기사의 차별성에 미치는 영향 : 경제뉴스 콘텐츠를 중심으로김욱원중앙대학교 신문방송대학원2016국내석사RANK : 13880191원문보기음성듣기The rapid development of the internet and smart device technology has brought a large reform in the media environment after the 2000s. The media environment which was structured in the existing printed media and broadcasting media, has changed in how information has been relayed on online media and portal site, as well as, internet social network services.This quantitative explosion of the media environment brought severe competition of ‘click’ through rate, which has been criticized as‘abusing article mass production’.These changes caused not only loss of customer’s trust, but also a vicious circle of financial difficulty. The Media struggled with the production of competitive contents as a way to survive and utilize the Big Data in journalism which has attracted much attention recently. In this study, it tries to depict how the Utilized Big Data in the economic news contents, can present the differences in terms of: reliability, objectivity, depth, as well as an easy read, which is compared with existing general articles, that only provide a consistency of text or text combined with pictures. Firstly, I had struggled with traditional ways of news produce and Big Data journalism, by examining this previous study and I suggested this subject of inquiry builds on earlier work.This study concludes on three types of articles that consist with text only, and combination with pictures, as well as, the combination of Big Data. They also include to the first-line journalists and examination of which these articles were more specific among them in terms of reliability, objectivity, depth, and legibility.The results indicated that the economic news contents by using Big Data hasdifferent influence on all the entries that provided reliability, objectivity, depth, and readability.This study showed that experts’ content by Utilized Big Data in economic news, affect considerably the internet media environment.Overall, this study has great significance. It presents that the comparison of existing journalism practices and news contents do Utilize the Big Data by the aiming at the front-line journalist groups and making the bigger headlines.Furthermore, a follow-up study, I am certain the success results of the differences in news contents are not only by Utilizing Big Data, but are also on various points of view. 2000년대 이후 인터넷과 스마트 디바이스 기술의 급속한 발전은 미디어 환경의 혁명적 변화를 몰고 왔다. 기존 인쇄 매체와 방송 매체로 구조화 되어 있던 미디어 환경은 인터넷을 기반으로 폭발적으로 증가하는 온라인 매체와 포털 사이트 및 소셜네트워크 서비스 등 정보전달 방식에 있어서도 큰 변혁이 일었다. 이 같은 미디어의 양적 폭발은 인터넷상에서 클릭 수 경쟁으로 이어져 ‘낚시성 기사’와 ‘어뷰징’의 남발 등 차별성 없는 기사만 양산한다는 비판에 직면하였다. 이 같은 사태는 뉴스에 대한 수용자들의 신뢰 하락을 불러왔고 결국 미디어의 경영 악화로 이어지는 악순환이 되풀이되고 있다. 미디어들은 이를 타개하기 위한 생존방안으로 경쟁력을 갖춘 독자적인 콘텐츠 생산을 고민하게 되었고 그 방안 중 하나로 최근 빅데이터를 활용한 저널리즘이 주목받고 있다.   본 연구는 ‘빅데이터를 활용한 경제뉴스 콘텐츠가 기존의 일반적인 텍스트로 구성된 기사, 텍스트와 사진이 결합된 기사와 비교하여 신뢰성, 객관성, 심층성, 가독성 측면에서 어떠한 차별성을 보이는가?’라는 연구문제를 제시하고 연구를 진행하였다. 우선 선행연구들을 조사하여 전통적인 뉴스생산 방식과 빅데이터 저널리즘에 대한 고찰을 하였고, 이를 기반으로 연구문제를 제시하고 연구를 진행하였다. 연구는 텍스트로만 구성된 기사와 텍스트+사진 기사, 텍스트+빅데이터 기사 등 세 가지 유형의 기사를 설문 대상자인 일선 취재기자들에게 제시하고 어떤 유형의 기사가 신뢰성, 객관성, 심층성, 가독성 측면에서 가장 차별성을 갖는가를 조사하였다.   연구 결과는 빅데이터를 활용한 경제뉴스 콘텐츠가 신뢰성, 객관성, 심층성, 가독성 등 4개 항목 모두에서 가장 차별적인 영향을 갖는 것으로 나타났다.    수없이 범람하는 인터넷상의 경제뉴스 콘텐츠가 독자적인 차별성을 갖추기 위한 한 방안으로 빅데이터의 활용이 상당히 효과적일 수 있음을 확인한 결과이다.   본 연구는 빅데이터를 실제 뉴스보도에 활용한 사례를 제시하여 기존 전통적인 뉴스 취재방식과 차별화되는 점을 비교하였다는 점과 실험집단을 기사 작성과 평가에 전문성을 갖춘 일선 취재기자 그룹을 대상으로 하여 연구 결과의 신뢰성을 높였다는 점에서 의의가 있다.   향후 후속연구를 통하여 빅데이터 뿐만 아니라 다양한 각도에서 뉴스콘텐츠의 차별성을 확보할 수 있는 방안이 도출되기를 기대한다.\n",
      "원문보기\n",
      "음성듣기\n",
      "results of the analysis system. weather and humidity based on thesentg119구조대의 승강기 갇힘 구조출동 및 119안전센터의 소방시설 오작동(비화재보) 관련 119생활안전대의 출동 데이터를 원자료(Raw Data)로 하여 빅데이터 분석시스템을 통해 상관관계를 분석해 보고, 그 결과를 바탕으로 온도·습도 기상인자와 119출동과의 상관관계를 규명 및 비화재보 119 출동 빈도수 경감 방안을 제언하고자 한다. ABSTRACT 및 119안전센터 생활안전대의 생활민원 출동 패턴이 존재할 것으로 판단된다. 빈번함을 할 수 있었다. \n",
      "원문보기\n",
      "목차검색조회\n",
      "음성듣기\n",
      "Key words: big data, restaurants evaluation application based on big data, perceived usefulness, intention to useshows that usefulness affects high influence, which means that it depends on occupations. dents from other occupations only showed positive influence of perceived usefulness regarding information quality.iation.ation regardless system quality of application.motivations. xperienced technology(application).도와 레스토랑에 대한 평점 및 정보의 일관성에 대해 매우 중요하게 생각하며 만족하고 있음을 반영한다. 였다.\n",
      "원문보기\n",
      "목차검색조회\n",
      "음성듣기\n",
      "President Moon Jae-in embodied the ‘Data Highway Construction’ of 2018, which is the core of the ‘Big Data Policy’ that the current government is pursuing, and National Information Society Agency(NIA) provided the theoretical foundation.nal Information Society Agency(NIA).\n",
      "원문보기\n",
      "목차검색조회\n",
      "9빅데이터를 활용한 자동차판매량 예측방안 연구이영환호서대학교2015국내석사RANK : 13880191원문보기목차검색조회음성듣기자동차 연비에 대한 실시간 키워드 검색 데이터 분석을 통해 자동차 단기 판매량의 예측이 가능할 것인지를 연구하고, 비전문가도 활용이 가능한 네이버 트렌드를 활용하여 빅데이터가 전문적인 영역이 아니라는 것을 설명함.연구결과는 실시간 데이터의 확보 및 다양한 이벤트 요소의 조합으로 실시간 빅데이터 모니터링을 통해 자동차 판매예측이 가능하고, 결과 데이터를 생산계획에 반영한다면 자동차 제조사 입장에서 오더 예측의 정합성이 향상될 것이며, 완성제품의 운영재고를 현격히 최소화 할 수 있음. 또한, 즉시 생산/ 판매의 가능성 향상으로 현금흐름이 빨라짐에 따라 경영성과의 향상을 기대할 수 있음. 그리고, 상시 오픈된 빅 데이터를 활용하여 우리 생활속의 다양한 예측이 가능함.\n",
      "원문보기\n",
      "목차검색조회\n",
      "음성듣기\n",
      "첫째, 4차 산업혁명 기술이 확산되는 경영환경 변화로 경쟁자 압박, 규정의 지원이 새로운 핵심요인으로 발견되었으며, 이는 시장경쟁자의 선제적 빅데이터 도입에 따른 압박감과 빅데이터 활용을 지원할 규정지원의 중요성이 커져감에 따라 핵심요인으로 인식된 것이라고 분석된다. 둘째, 개인관점에서 모든 요인이 핵심요인으로 나타난 것은 ICT기반의 업무환경 속에 능동적으로 적응하여 성과를 향상시켜야 하는 조직원의 변화된 인식이 반영된 것으로 해석되며, 성공적인 빅데이터 활용을 위하여 조직원이 중요한 고려요인임을 확인할 수 있었다. 셋째, 빅데이터 사용경험이 있는 집단의 리더십, 전략기획 수준이 높고 그 차이가 유의하게 나타남으로써, 빅데이터를 활용하는 것이 경영품질 수준을 높일 수 있다는 영향관계를 처음으로 확인하였다. 따라서 이러한 연구결과를 바탕으로 정부차원에서 다양한 중소기업 업종에서 활용할 수 있는 범용 빅데이터 시스템을 개발하여 지원한다면, 중소기업이 경영품질 향상을 통해 기업규모를 성장시켜 나가는데 도움이 될 수 있을 것이다. 넷째, 국가품질상 도전과정을 통해 경영품질이 기업 내에 내재화 되고, 이를 기반으로 지속가능경영을 추구해 나갈 수 있도록 정부의 적극적인 국가품질상 진흥정책의 확대가 필요하다. 이와 같이 본 연구는 기업의 빅데이터 활용과 경영품질 향상에 대한 이론적, 실용적 시사점을 제공하였다.s of challenging the national quality awards. Thus, this study provided the theoretical and practical implications for the Use of Big Data and Improvement of Management Quality. 최근 세계경제포럼(WEF)에서 ‘4차 산업혁명’이라는 용어가 언급된 이후, 정보통신기술(ICT)기반의 새로운 차세대 산업혁명으로 대표되면서 전 세계로 빠르게 확산되고 있다. 초 연결, 초 지능의 특징에 의해 데이터가 폭발적으로 증가되고, 이를 의미 있는 정보로 분석하여 경제적 가치를 창출하는 빅데이터는 4차 산업혁명의 핵심 기반기술로써 산업전반에 큰 파급효과를 불러오고 있다.\n",
      "원문보기\n",
      "목차검색조회\n",
      "음성듣기\n",
      "키워드 빅데이터 (으)로  5,291 건 검색\n",
      "1.번호: 1\n",
      "2.논문제목: 빅데이터 기반 시공간 센서 데이터 처리 시스템\n",
      "3.저자: 김장수\n",
      "4.소속기관: 건국대학교\n",
      "\n",
      "\n",
      "1.번호: 2\n",
      "2.논문제목: 빅데이터 마이닝에 의한 공시지가 민원의 시공간적 특성 분석\n",
      "3.저자: 조태인\n",
      "4.소속기관: 인천대학교\n",
      "\n",
      "\n",
      "1.번호: 3\n",
      "2.논문제목: 빅데이터를 이용한 “빅데이터” 관련 국내 연구 동향 분석 : 공학, 사회과학  KCI 등재/등재 후보지 중심으로\n",
      "3.저자: 전지영\n",
      "4.소속기관: 한밭대학교 창업경영대학원\n",
      "\n",
      "\n",
      "1.번호: 4\n",
      "2.논문제목: 빅데이터 응용사례 분석을 통한 소스데이터 유형 분류 : BI&A 응용분야와 U-City 서비스 분류체계를 중심으로\n",
      "3.저자: 이현구\n",
      "4.소속기관: 단국대학교 대학원\n",
      "\n",
      "\n",
      "1.번호: 5\n",
      "2.논문제목: 빅데이터를 활용한 뉴스 콘텐츠가 기사의 차별성에 미치는 영향 : 경제뉴스 콘텐츠를 중심으로\n",
      "3.저자: 김욱원\n",
      "4.소속기관: 중앙대학교 신문방송대학원\n",
      "\n",
      "\n",
      "1.번호: 6\n",
      "2.논문제목: 빅데이터 분석을 통해 살펴본 비화재출동 경감방안에 관한 연구\n",
      "3.저자: 백진우\n",
      "4.소속기관: 조선대학교 대학원\n",
      "\n",
      "\n",
      "1.번호: 7\n",
      "2.논문제목: 빅데이터 기반 레스토랑 평가 애플리케이션의 특성과 이용동기가 소비자 이용의도에 미치는 영향\n",
      "3.저자: 임영희\n",
      "4.소속기관: 세종대학교 관광대학원\n",
      "\n",
      "\n",
      "1.번호: 8\n",
      "2.논문제목: 한국의 '빅데이터 정책' 형성에 관한 연구 : 준정부기관의 정책기업가 역할을 중심으로\n",
      "3.저자: 정진우\n",
      "4.소속기관: 전북대학교 행정대학원\n",
      "\n",
      "\n",
      "1.번호: 9\n",
      "2.논문제목: 빅데이터를 활용한 자동차판매량 예측방안 연구\n",
      "3.저자: 이영환\n",
      "4.소속기관: 호서대학교\n",
      "\n",
      "\n",
      "1.번호: 10\n",
      "2.논문제목: 조직, 개인 그리고 경영품질 관점에서 기업의 빅데이터 활용의도에 영향을 미치는 핵심요인에 관한 연구\n",
      "3.저자: 신수행\n",
      "4.소속기관: 전남대학교\n",
      "\n",
      "\n",
      "1.번호: 11\n",
      "2.논문제목: 빅데이터 활용 요인이 경영성과에 미치는 영향에 관한 연구\n",
      "3.저자: 이충형\n",
      "4.소속기관: 고려대학교 기술경영전문대학원\n",
      "\n",
      "\n",
      "1.번호: 12\n",
      "2.논문제목: 빅데이터로서 수사기록 보존폐기에 대한 연구\n",
      "3.저자: 홍승아\n",
      "4.소속기관: 서울대학교 융합과학기술대학원\n",
      "\n",
      "\n",
      "1.번호: 13\n",
      "2.논문제목: 빅데이터 로그를 이용한 실시간 예측분석시스템 설계 및 구현\n",
      "3.저자: 이상준\n",
      "4.소속기관: 高麗大學校 情報經營工學專門大學院\n",
      "\n",
      "\n",
      "1.번호: 14\n",
      "2.논문제목: 빅데이터 분석을 활용한 지역맞춤형 평생교육프로그램 개발 모형\n",
      "3.저자: 김현성\n",
      "4.소속기관: 대구한의대학교 대학원\n",
      "\n",
      "\n",
      "1.번호: 15\n",
      "2.논문제목: IPA기법을 활용한 제조분야의 빅데이터 수용도 분석 : IT 분야 제조 A社 중심\n",
      "3.저자: 주혁\n",
      "4.소속기관: 성균관대학교 일반대학원\n",
      "\n",
      "\n",
      "1.번호: 16\n",
      "2.논문제목: 빅데이터를 활용한 비즈니스 모델 개발 : 철도공사 사례를 중심으로\n",
      "3.저자: 심승식\n",
      "4.소속기관: 忠南大學校 大學院\n",
      "\n",
      "\n",
      "1.번호: 17\n",
      "2.논문제목: 빅 데이터 활용에 있어서 개인정보보호 문제점 및 개선방안(PIMS 활용)\n",
      "3.저자: 김용빈\n",
      "4.소속기관: 강원대학교 산업대학원\n",
      "\n",
      "\n",
      "1.번호: 18\n",
      "2.논문제목: 빅데이터 산업의 활성화에 따른 개인정보 보호에 관한 연구\n",
      "3.저자: 차상휘\n",
      "4.소속기관: 전북대학교\n",
      "\n",
      "\n",
      "1.번호: 19\n",
      "2.논문제목: 빅 데이터 플랫폼을 이용한 풍력 발전기 SCADA 데이터 분석의 시각화 기술 연구\n",
      "3.저자: 박상준\n",
      "4.소속기관: 단국대학교\n",
      "\n",
      "\n",
      "1.번호: 20\n",
      "2.논문제목: 빅데이터 분석을 통한 공기업 이미지 및 주요정책 평가 연구 : 한국토지주택공사(LH) 사례를 중심으로\n",
      "3.저자: 석지연\n",
      "4.소속기관: 고려대학교\n",
      "\n",
      "\n",
      "1.번호: 21\n",
      "2.논문제목: 빅데이터를 위한 분석기술 활용방안 연구\n",
      "3.저자: 박준규\n",
      "4.소속기관: 세종대학교 대학원\n",
      "\n",
      "\n",
      "1.번호: 22\n",
      "2.논문제목: 빅데이터를 활용한 항공운송서비스의 혁신사례 연구\n",
      "3.저자: 조유나\n",
      "4.소속기관: 韓國航空大學校\n",
      "\n",
      "\n",
      "1.번호: 23\n",
      "2.논문제목: 빅데이터를 활용한 광고 스토리텔링 연구 : 웹 드라마를 중심으로\n",
      "3.저자: 정한솔\n",
      "4.소속기관: 국민대학교 테크노디자인전문대학원\n",
      "\n",
      "\n",
      "1.번호: 24\n",
      "2.논문제목: 빅데이터 교육역량 강화를 위한  H-R도 탐구 프로그램 개발\n",
      "3.저자: 김미림\n",
      "4.소속기관: 한국교원대학교 대학원\n",
      "\n",
      "\n",
      "1.번호: 25\n",
      "2.논문제목: 기업의 위기관리를 위한 빅데이터에 관한 연구\n",
      "3.저자: 손기동\n",
      "4.소속기관: 인하대학교 일반대학원\n",
      "\n",
      "\n",
      "1.번호: 26\n",
      "2.논문제목: 빅데이터 분석을 통한 전통마을 관광 개선 방안\n",
      "3.저자: 정동현\n",
      "4.소속기관: 숭실대학교 대학원\n",
      "\n",
      "\n",
      "요청하신 작업이 모두 완료되었습니다\n",
      "요청하신 데이터 수집 작업이 정상적으로 완료되었습니다\n"
     ]
    }
   ],
   "source": [
    "# riss.kr 에서 특정 키워드로 논문 / 학술 자료 검색하기\n",
    "\n",
    "#Step 1. 필요한 모듈을 로딩합니다\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.by import By\n",
    "# from selenium.webdriver.common.keys import Keys\n",
    "# from selenium.webdriver.chrome.service import Service\n",
    "import time          \n",
    "\n",
    "#Step 2. 사용자에게 검색 관련 정보들을 입력 받고 3. 파일 이름 정하기\n",
    "query_txt ='빅데이터'\n",
    "ft_name = 'C:\\\\Users\\\\Playdata\\\\Desktop\\\\BigLeader\\\\Crawaler\\\\py_temp\\\\riss.txt'\n",
    "fc_name = 'C:\\\\Users\\\\Playdata\\\\Desktop\\\\BigLeader\\\\Crawaler\\\\py_temp\\\\riss.csv'\n",
    "fx_name = 'C:\\\\Users\\\\Playdata\\\\Desktop\\\\BigLeader\\\\Crawaler\\\\py_temp\\\\riss.xls'\n",
    "\n",
    "#Step 4. 크롬 드라이버 설정 및 웹 페이지 열기\n",
    "driver = webdriver.Chrome(ca.install())\n",
    "driver.get('https://www.riss.kr/')\n",
    "\n",
    "time.sleep(5)\n",
    "driver.maximize_window()\n",
    "\n",
    "#Step 5. 자동으로 검색어 입력 후 6 학위논문 클릭\n",
    "driver.find_element(By.ID,'query').send_keys(query_txt+ '\\n')\n",
    "driver.find_element(By.LINK_TEXT,'학위논문').click()\n",
    "time.sleep(2)\n",
    "\n",
    "#Step 7.Beautiful Soup 로 본문 내용만 추출하기\n",
    "soup_1 = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "content_1 = soup_1.find('div','srchResultListW').find_all('li')\n",
    "\n",
    "for i in content_1 :\n",
    "    print(i.get_text().replace(\"\\n\",\"\"))\n",
    "\n",
    "#Step 8. 총 검색 건수를 보여주고 수집할 건수 입력받기\n",
    "import math\n",
    "total_cnt = soup_1.find('div','searchBox pd').find('span','num').get_text()\n",
    "print('키워드 %s (으)로  %s 건 검색' %(query_txt,total_cnt))\n",
    "\n",
    "collect_cnt = int(input(' 몇 건을 수집하시겠습니까?: '))\n",
    "collect_page_cnt = math.ceil(collect_cnt / 10)\n",
    "\n",
    "\n",
    "#Step 9. 각 항목별로 데이터를 추출하여 리스트에 저장하기\n",
    "no2 = [ ]        #번호 저장\n",
    "title2 = [ ]     #논문제목 저장\n",
    "writer2 = [ ]    #논문저자 저장\n",
    "org2 = [ ]       #소속기관 저장\n",
    "no = 1\n",
    "\n",
    "for a in range(1, collect_page_cnt + 1) :\n",
    "    \n",
    "    soup_2 = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    content_2 = soup_2.find('div','srchResultListW').find_all('li')\n",
    "    \n",
    "    for b in content_2 : \n",
    "        #1. 논문제목 있을 경우만\n",
    "        try :\n",
    "            title = b.find('p','title').get_text()\n",
    "        except :\n",
    "            continue\n",
    "        else :\n",
    "            f = open(ft_name, 'a' , encoding=\"UTF-8\")\n",
    "            \n",
    "            print('1.번호:',no)\n",
    "            no2.append(no)\n",
    "            f.write('\\n'+'1.번호:' + str(no))\n",
    "\n",
    "            print('2.논문제목:',title)\n",
    "            title2.append(title)\n",
    "            f.write('\\n' + '2.논문제목:' + title)\n",
    "            \n",
    "            writer = b.find('span','writer').get_text()\n",
    "            print('3.저자:',writer)\n",
    "            writer2.append(writer)\n",
    "            f.write('\\n' + '3.저자:' + writer)\n",
    "\n",
    "            org = b.find('span','assigned').get_text()\n",
    "            print('4.소속기관:' , org)\n",
    "            org2.append(org)\n",
    "            f.write('\\n' + '4.소속기관:' + org + '\\n')\n",
    "            \n",
    "            f.close( )\n",
    "            \n",
    "            no += 1\n",
    "            print(\"\\n\")\n",
    "            \n",
    "            if no > collect_cnt :\n",
    "                break\n",
    "\n",
    "            time.sleep(1)        # 페이지 변경 전 1초 대기 \n",
    "\n",
    "    a += 1 \n",
    "    b = str(a)\n",
    "\n",
    "    try :\n",
    "        driver.find_element(By.LINK_TEXT ,'%s' %b).click() \n",
    "    except :\n",
    "        driver.find_element(By.LINK_TEXT('다음 페이지로')).click()\n",
    "        \n",
    "print(\"요청하신 작업이 모두 완료되었습니다\")\n",
    "\n",
    "# Step 10. 수집된 데이터를 xls와 csv 형태로 저장하기\n",
    "import pandas as pd \n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['번호']=no2\n",
    "df['제목']=pd.Series(title2)\n",
    "df['저자']=pd.Series(writer2)\n",
    "df['소속(발행)기관']=pd.Series(org2)\n",
    "\n",
    "# xls 형태로 저장하기\n",
    "df.to_excel(fx_name,index=False, encoding=\"utf-8\" , engine='openpyxl')\n",
    "\n",
    "# csv 형태로 저장하기\n",
    "df.to_csv(fc_name,index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print('요청하신 데이터 수집 작업이 정상적으로 완료되었습니다')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "8965150514684192fd1d81b86341baebb0ab118aa72b57568cb073ce4741e3b7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
